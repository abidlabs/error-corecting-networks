{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47959</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47959</td>\n",
       "      <td>35178</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 34297</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>52573</td>\n",
       "      <td>145807</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #     Word      POS      Tag\n",
       "count             47959  1048575  1048575  1048575\n",
       "unique            47959    35178       42       17\n",
       "top     Sentence: 34297      the       NN        O\n",
       "freq                  1    52573   145807   887908"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
     ]
    }
   ],
   "source": [
    "print(df['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tag_set = ['B-geo', 'B-gpe', 'B-org', 'B-per', 'B-tim', 'I-geo',\n",
    "                   'I-gpe', 'I-org', 'I-per', 'I-tim', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "y = [[label if label in reduced_tag_set else 'O' for label in y_i] for y_i in y]  # reduce tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMB-Simple-Blurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_labels(y, frac):\n",
    "    y_new = []\n",
    "    error_array = []\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        error_array.append(list())\n",
    "        y_new.append(list())\n",
    "        change_steps = 0\n",
    "        change_to = None\n",
    "        \n",
    "        for j in range(len(y[i])):\n",
    "            \n",
    "            current_tag = y[i][j]\n",
    "            if current_tag=='B-geo' and  j >= 3 and np.random.random() < frac:\n",
    "                for k in range(3):\n",
    "                    y_new[i][j - k - 1] = current_tag\n",
    "                    error_array[i][j - k - 1] = True\n",
    "                \n",
    "                y_new[i].append(current_tag)\n",
    "                error_array[i].append(False)\n",
    "            else:\n",
    "                error_array[i].append(False)\n",
    "                y_new[i].append(current_tag)\n",
    "        \n",
    "    return y_new, error_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new, error_train_array = blur_labels(y_train, frac=0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tags: 818288\n",
      "Num errs: 49359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06031983849207125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sum([len(a) for a in error_train_array]); print('Num tags:', t)\n",
    "e = sum([sum(a) for a in error_train_array]); print('Num errs:', e)\n",
    "e/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37407\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8357404453107364\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.86      0.91      0.89      7440\n",
      "       B-gpe       0.96      0.94      0.95      3125\n",
      "       B-org       0.82      0.74      0.78      4049\n",
      "       B-per       0.85      0.84      0.84      3506\n",
      "       B-tim       0.92      0.88      0.90      4072\n",
      "       I-geo       0.82      0.78      0.80      1486\n",
      "       I-gpe       0.78      0.42      0.55        43\n",
      "       I-org       0.82      0.79      0.81      3410\n",
      "       I-per       0.86      0.90      0.88      3583\n",
      "       I-tim       0.86      0.76      0.81      1352\n",
      "           O       0.99      0.99      0.99    177386\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    209452\n",
      "   macro avg       0.87      0.81      0.84    209452\n",
      "weighted avg       0.97      0.97      0.97    209452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "clean_precision, clean_recall, clean_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787772411624082\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train_new)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.38      0.89      0.53      7440\n",
      "       B-gpe       0.96      0.91      0.93      3125\n",
      "       B-org       0.79      0.74      0.76      4049\n",
      "       B-per       0.85      0.83      0.84      3506\n",
      "       B-tim       0.92      0.84      0.88      4072\n",
      "       I-geo       0.83      0.66      0.73      1486\n",
      "       I-gpe       0.86      0.42      0.56        43\n",
      "       I-org       0.81      0.78      0.79      3410\n",
      "       I-per       0.85      0.89      0.87      3583\n",
      "       I-tim       0.87      0.73      0.79      1352\n",
      "           O       0.99      0.94      0.97    177386\n",
      "\n",
      "   micro avg       0.93      0.93      0.93    209452\n",
      "   macro avg       0.83      0.78      0.79    209452\n",
      "weighted avg       0.95      0.93      0.94    209452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "dirty_precision, dirty_recall, dirty_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-the press freedom group reporters without borders has condemned the decision by VENEZUELAN PRESIDENT HUGH CHAVEZ to shut down one of the country 's oldest television stations the group issued a statement FRIDAY calling the move \" a serious attack against editorial pluralism . \" \n",
      "-a group spokesman said the project was about 85 percent complete . \n",
      "-his comments came as RUSSIAN PRESIDENT VLADIMIR PUTIN and VENEZUELAN leader HUGO CHAVEZ met in MOSCOW . \n",
      "-before the center opened THURSDAY , *CUSTOMS *OFFICES *ALONG RUSSIA 's expansive border regions *COMMUNICATED *WITH *THEIR MOSCOW headquarters primarily by telephone . \n",
      "-he blames ICELAND 's economic calamity on commercial bankers . \n",
      "-a police spokeswoman said a 46-year-old man had been arrested APRIL 25 and questioned over an assault in west LONDON . \n",
      "-IRAN says its nuclear program is only for peaceful purposes . \n",
      "-the KYRGYZ staged a major revolt against the TSARIST EMPIRE in 1916 in which almost one-sixth of the KYRGYZ population was killed . \n",
      "-the statement in particular referred to last month 's closure of a popular supplement to the CHINA YOUTH DAILY . \n",
      "-he praised world leaders *FOR *COMING *TO WASHINGTON to seek a solution to the global financial crisis , saying the matter requires a \" coordinated global response . \" \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_train[i]):\n",
    "        word = word['word.lower()']\n",
    "        if error_train_array[i][w]:\n",
    "            print('*', end='')            \n",
    "        if y_train_new[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*city officials say the students ' return will sizably increase the city 's population and bring in new consumer dollars . \n",
      "-the medicines attack the aids virus at different points in its replication cycle . \n",
      "-MR. BUSH recently wrapped up a nationwide tour promoting his plans for SOCIAL SECURITY . \n",
      "-south KOREAN media report MONDAY that a recent *POLITICAL *COMMENTARY *ON *NORTH KOREAN radio , heard last THURSDAY , referred to comments by the elder KIM saying his son or even his grandson should complete his work if he falls short of completing the country 's \" revolution . \" \n",
      "-PROFESSOR COMERIO talks about the scope of re-building , the *LONG-RANGE *OUTLOOK *FOR *RECOVERY *AND *HOW HAITI 's devastation compares with other similar earthquake disasters . \n",
      "-last year , *AFGHANISTAN discovered cases of the h5n1 virus in birds , but not humans . \n",
      "-U.S. officials do not publicly comment on the drone strikes , which have *RAISED *TENSIONS *BETWEEN PAKISTAN *AND *THE UNITED STATES in the *past . \n",
      "-meanwhile , violence in AFGHANISTAN continues . \n",
      "-olympic *TICKETING *CENTER *HEAD *RONG *JUN said TUESDAY that tickets to the opening ceremony , basketball and diving competitions have been the best sellers . \n",
      "-in western and *SOUTHERN *INDIA , more than 500 people have been killed and millions left homeless since the annual monsoon rains began in JUNE . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_test[i]):\n",
    "        word = word['word.lower()']\n",
    "        if y_pred[i][w] != y_test[i][w]:\n",
    "            print('*', end='')\n",
    "            \n",
    "        if y_pred[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Try to Fix the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the clean F1 is: **0.84** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_method(error_pred, error_array, X, y_corrected):\n",
    "    # measure what percent of errors are fixed\n",
    "    np = 0; nn=0; tp = 0; fp = 0;\n",
    "    for i in range(len(error_pred)):\n",
    "        for j in range(len(error_pred[i])):\n",
    "            if error_pred[i][j] and error_pred[i][j] == error_array[i][j]:\n",
    "                tp += 1\n",
    "            elif error_pred[i][j]:\n",
    "                fp += 1\n",
    "            if error_array[i][j]:\n",
    "                np += 1\n",
    "            else:\n",
    "                nn += 1\n",
    "\n",
    "    \n",
    "    print(\"TP errors detected: {}\".format(tp/np))\n",
    "    print(\"FP errors detected: {}\".format(fp/nn)) \n",
    "\n",
    "    # measure accuracy\n",
    "    crf.fit(X, y_corrected)\n",
    "    y_pred = crf.predict(X_test)\n",
    "    f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(\"F1 score on trained model: {}\".format(f1_score))\n",
    "    \n",
    "    report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision, recall, f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "    print(flat_classification_report(y_test, y_pred))\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudolabeled from Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudolabeled_on_validation(X_val, y_val):\n",
    "    \n",
    "    crf.fit(X_val, y_val)\n",
    "    y_pred = crf.predict(X_train)\n",
    "\n",
    "    error_pred = []\n",
    "    y_corrected = []\n",
    "\n",
    "    for i in range(len(y_pred)):    \n",
    "        error_pred.append([])\n",
    "        y_corrected.append([])\n",
    "\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if not(y_pred[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with X, y, neighboring y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_x_y_neighboring_y(X_val, y_val, num_x_keys=1):\n",
    "    keys_prioritized = ['word.isupper()', 'word.istitle()', 'word.isdigit()', '+1:word.istitle()', \n",
    "                        '+1:word.isupper()', 'BOS', 'bias',  'word.lower()', 'word[-3:]', 'word[-2:]',\n",
    "                        '+1:word.lower()', 'postag', 'postag[:2]', '+1:postag', '+1:postag[:2]', \n",
    "                        '-1:postag', '-1:postag[:2]', '-1:word.istitle()', '-1:word.lower()',\n",
    "                        '-1:word.isupper()', 'EOS']\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_val_sub = X_val[i][j].copy()\n",
    "            else:\n",
    "                X_val_sub = {k: X_val[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_val[i][j]}\n",
    "            correction_network_input[i].append(X_val_sub)\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j]     \n",
    "            if j >= 1:\n",
    "                correction_network_input[i][j]['y-1'] = y_val_pred[i][j-1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                correction_network_input[i][j]['y-2'] = y_val_pred[i][j-2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 1:\n",
    "                correction_network_input[i][j]['y+1'] = y_val_pred[i][j+1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 2:\n",
    "                correction_network_input[i][j]['y+2'] = y_val_pred[i][j+2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+2'] = 'N'\n",
    "\n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_train_sub = X_train[i][j].copy()\n",
    "            else:\n",
    "                X_train_sub = {k: X_train[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_train[i][j]}\n",
    "            X_expanded[i].append(X_train_sub)\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            if j >= 1:\n",
    "                X_expanded[i][j]['y-1'] = y_train_new[i][j-1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                X_expanded[i][j]['y-2'] = y_train_new[i][j-2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 1:\n",
    "                X_expanded[i][j]['y+1'] = y_train_new[i][j+1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 2:\n",
    "                X_expanded[i][j]['y+2'] = y_train_new[i][j+2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+2'] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with y, neighboring y only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_y_neighboring_y(X_val, y_val, num_ys=1):\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            correction_network_input[i].append(dict())\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j] \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = y_val_pred[i][j-k]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_val_pred[i]) - k:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = y_val_pred[i][j+1]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = 'N'\n",
    "    \n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            X_expanded[i].append(dict())\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = y_train_new[i][j-k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_train_new[i]) - k:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = y_train_new[i][j+k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do results change based on markov blanket size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "X_val_ = X_val[:n]\n",
    "y_val_ = y_val[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9476893778236999\n",
      "FP errors detected: 0.06741584723687102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on trained model: 0.5963959435549879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.69      0.84      0.76      7440\n",
      "       B-gpe       0.89      0.62      0.73      3125\n",
      "       B-org       0.53      0.44      0.48      4049\n",
      "       B-per       0.74      0.61      0.67      3506\n",
      "       B-tim       0.93      0.57      0.71      4072\n",
      "       I-geo       0.48      0.62      0.54      1486\n",
      "       I-gpe       0.00      0.00      0.00        43\n",
      "       I-org       0.54      0.47      0.51      3410\n",
      "       I-per       0.77      0.72      0.75      3583\n",
      "       I-tim       0.76      0.31      0.44      1352\n",
      "           O       0.97      0.99      0.98    177386\n",
      "\n",
      "   micro avg       0.93      0.93      0.93    209452\n",
      "   macro avg       0.66      0.56      0.60    209452\n",
      "weighted avg       0.93      0.93      0.93    209452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppr, pre, pf1 = pseudolabeled_on_validation(X_val_, y_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9365262667396017\n",
      "FP errors detected: 0.007696419305293466\n",
      "F1 score on trained model: 0.7658431168329041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.85      0.88      0.86      7440\n",
      "       B-gpe       0.97      0.92      0.94      3125\n",
      "       B-org       0.82      0.70      0.75      4049\n",
      "       B-per       0.86      0.82      0.84      3506\n",
      "       B-tim       0.92      0.82      0.87      4072\n",
      "       I-geo       0.78      0.73      0.76      1486\n",
      "       I-gpe       0.00      0.00      0.00        43\n",
      "       I-org       0.83      0.75      0.79      3410\n",
      "       I-per       0.85      0.88      0.86      3583\n",
      "       I-tim       0.82      0.71      0.76      1352\n",
      "           O       0.99      0.99      0.99    177386\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    209452\n",
      "   macro avg       0.79      0.75      0.77    209452\n",
      "weighted avg       0.97      0.97      0.97    209452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_y_neighboring_y(X_val_, y_val_, num_ys=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9195486132214996\n",
      "FP errors detected: 0.006711933091351738\n",
      "F1 score on trained model: 0.7683004293936396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.83      0.91      0.87      7440\n",
      "       B-gpe       0.97      0.92      0.94      3125\n",
      "       B-org       0.79      0.71      0.75      4049\n",
      "       B-per       0.86      0.82      0.84      3506\n",
      "       B-tim       0.93      0.81      0.87      4072\n",
      "       I-geo       0.77      0.76      0.76      1486\n",
      "       I-gpe       0.00      0.00      0.00        43\n",
      "       I-org       0.83      0.75      0.79      3410\n",
      "       I-per       0.86      0.89      0.88      3583\n",
      "       I-tim       0.83      0.73      0.78      1352\n",
      "           O       0.99      0.99      0.99    177386\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    209452\n",
      "   macro avg       0.79      0.75      0.77    209452\n",
      "weighted avg       0.97      0.97      0.97    209452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_x_y_neighboring_y(X_val_, y_val_, num_x_keys=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
