{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47959</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47959</td>\n",
       "      <td>35178</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 4603</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>52573</td>\n",
       "      <td>145807</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #     Word      POS      Tag\n",
       "count            47959  1048575  1048575  1048575\n",
       "unique           47959    35178       42       17\n",
       "top     Sentence: 4603      the       NN        O\n",
       "freq                 1    52573   145807   887908"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
     ]
    }
   ],
   "source": [
    "print(df['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tag_set = ['B-geo', 'B-gpe', 'B-org', 'B-per', 'B-tim', 'I-geo',\n",
    "                   'I-gpe', 'I-org', 'I-per', 'I-tim', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "y = [[label if label in reduced_tag_set else 'O' for label in y_i] for y_i in y]  # reduce tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMB-Simple-Blurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_labels(y):\n",
    "    y_new = []\n",
    "    error_array = []\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        error_array.append(list())\n",
    "        y_new.append(list())\n",
    "        change_steps = 0\n",
    "        change_to = None\n",
    "        \n",
    "        for j in range(len(y[i])):\n",
    "            \n",
    "            current_tag = y[i][j]\n",
    "            num_blur = np.random.randint(1,4)\n",
    "            if current_tag=='B-geo' and  j >= num_blur:\n",
    "                for k in range(num_blur):\n",
    "                    y_new[i][j - k - 1] = current_tag\n",
    "                    error_array[i][j - k - 1] = True\n",
    "                \n",
    "                y_new[i].append(current_tag)\n",
    "                error_array[i].append(False)\n",
    "            else:\n",
    "                error_array[i].append(False)\n",
    "                y_new[i].append(current_tag)\n",
    "        \n",
    "    return y_new, error_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new, error_train_array = blur_labels(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tags: 818680\n",
      "Num errs: 50475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06165412615429716"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sum([len(a) for a in error_train_array]); print('Num tags:', t)\n",
    "e = sum([sum(a) for a in error_train_array]); print('Num errs:', e)\n",
    "e/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37407\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8386750589199572\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.85      0.91      0.88      7410\n",
      "       B-gpe       0.97      0.94      0.96      3191\n",
      "       B-org       0.81      0.72      0.76      4056\n",
      "       B-per       0.85      0.83      0.84      3386\n",
      "       B-tim       0.93      0.88      0.90      4042\n",
      "       I-geo       0.83      0.81      0.82      1492\n",
      "       I-gpe       0.77      0.50      0.61        40\n",
      "       I-org       0.81      0.77      0.79      3406\n",
      "       I-per       0.86      0.90      0.88      3524\n",
      "       I-tim       0.85      0.74      0.79      1300\n",
      "           O       0.99      0.99      0.99    177158\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    209005\n",
      "   macro avg       0.87      0.82      0.84    209005\n",
      "weighted avg       0.97      0.97      0.97    209005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "clean_precision, clean_recall, clean_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7885381281174536\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train_new)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.36      0.88      0.51      7410\n",
      "       B-gpe       0.97      0.93      0.95      3191\n",
      "       B-org       0.77      0.73      0.75      4056\n",
      "       B-per       0.84      0.83      0.84      3386\n",
      "       B-tim       0.92      0.85      0.89      4042\n",
      "       I-geo       0.84      0.67      0.75      1492\n",
      "       I-gpe       0.83      0.47      0.60        40\n",
      "       I-org       0.80      0.77      0.78      3406\n",
      "       I-per       0.85      0.89      0.87      3524\n",
      "       I-tim       0.84      0.72      0.78      1300\n",
      "           O       0.99      0.94      0.96    177158\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    209005\n",
      "   macro avg       0.82      0.79      0.79    209005\n",
      "weighted avg       0.95      0.92      0.93    209005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "dirty_precision, dirty_recall, dirty_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-AFGHAN officials say three police officers have been killed in two different suicide bombings TUESDAY . \n",
      "-the official count released TUESDAY shows that MR. MORALES ' MOVEMENT TOWARD SOCIALISM ( MAS ) party won 137 of the assembly 's 255 seats . \n",
      "-PRESIDENT BARACK OBAMA has said the $ 787 billion economic stimulus plan he signed within months of taking office has stopped the recession from getting worse . \n",
      "-lawmakers *IN SPAIN have voted to send about 400 troops to join anti-piracy patrols off the coast *OF SOMALIA . \n",
      "-the value *OF STARBUCKS ' shares has been falling sharply in RECENT months . \n",
      "-U.S. secretary of STATE NOMINEE CONDOLEEZZA RICE is facing a second and final day of confirmation hearings WEDNESDAY , after a first day that *FOCUSED *HEAVILY *ON IRAQ and repairing alliances strained by the conflict . \n",
      "-their statement said any terrorist activity targeting innocent people contradicts ISLAM 's concept of peace . \n",
      "-MR. CUMMINGS says he believes the meeting was to assure black leaders that any missteps in getting relief to hurricane victims would be corrected . \n",
      "-AL-RAI television FRIDAY quoted sources close to the kidnappers as saying the abductors have set the deadline . \n",
      "-in a separate *STATEMENT *, *THE U.S. military says troops killed ALI WALI , an explosives expert and member of the ANSAR AL-ISLAM terrorist group , during a counterterrorist raid in ( *THE MANSUR *DISTRICT *OF *) BAGHDAD on SATURDAY . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_train[i]):\n",
    "        word = word['word.lower()']\n",
    "        if error_train_array[i][w]:\n",
    "            print('*', end='')            \n",
    "        if y_train_new[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-officials say workers are still auditing results for *ABOUT *12 SHI'ITE *and *kurdish areas which reported unusually high totals of \" yes \" votes . \n",
      "-in the northern *CITY *OF MOSUL , police say a suicide car bombing targeting a police patrol killed at least nine people , including at least three policemen . \n",
      "-*SOME *SUNNI *ARAB politicians and tribal leaders complained that the operation endangers civilians and could lead to *GREATER *INSTABILITY *IN *SUNNI sections of the country . \n",
      "-*nebraska farmers agreed to sell wheat , beans and soy products to the CUBANS . \n",
      "-the attack occurred *IN NAD ALI district *OF AFGHANISTAN 's *OPIUM *PRODUCING *HEARTLAND *OF HELMAND province . \n",
      "-SAEB EREKAT , who was an *ARAFAT ally and former minister of negotiations , was left out . \n",
      "-RASHID ABU SHBAK , a senior security official said SATURDAY the measures include the disbanding of the DEPARTMENT OF PROTECTION AND SECURITY , a group gazans have nicknamed \" death squad . \" \n",
      "-curling is an ancient game which originated prior to the *1500S *IN SCOTLAND . \n",
      "-the strike and protests led the government to declare a state of *EMERGENCY *IN ORELLANA and *sucumbios provinces and to put them under military control . \n",
      "-but the government ruled out taking any action against the junior minister , saying prosecution could not take place on the basis of \" probability . \" \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_test[i]):\n",
    "        word = word['word.lower()']\n",
    "        if y_pred[i][w] != y_test[i][w]:\n",
    "            print('*', end='')\n",
    "            \n",
    "        if y_pred[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Try to Fix the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the clean F1 is: **0.84** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_method(error_pred, error_array, X, y_corrected):\n",
    "    # measure what percent of errors are fixed\n",
    "    np = 0; nn=0; tp = 0; fp = 0;\n",
    "    for i in range(len(error_pred)):\n",
    "        for j in range(len(error_pred[i])):\n",
    "            if error_pred[i][j] and error_pred[i][j] == error_array[i][j]:\n",
    "                tp += 1\n",
    "            elif error_pred[i][j]:\n",
    "                fp += 1\n",
    "            if error_array[i][j]:\n",
    "                np += 1\n",
    "            else:\n",
    "                nn += 1\n",
    "\n",
    "    \n",
    "    print(\"TP errors detected: {}\".format(tp/np))\n",
    "    print(\"FP errors detected: {}\".format(fp/nn)) \n",
    "\n",
    "    # measure accuracy\n",
    "    crf.fit(X, y_corrected)\n",
    "    y_pred = crf.predict(X_test)\n",
    "    f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(\"F1 score on trained model: {}\".format(f1_score))\n",
    "    \n",
    "    report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision, recall, f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "    print(flat_classification_report(y_test, y_pred))\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudolabeled from Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudolabeled_on_validation(X_val, y_val):\n",
    "    \n",
    "    crf.fit(X_val, y_val)\n",
    "    y_pred = crf.predict(X_train)\n",
    "\n",
    "    error_pred = []\n",
    "    y_corrected = []\n",
    "\n",
    "    for i in range(len(y_pred)):    \n",
    "        error_pred.append([])\n",
    "        y_corrected.append([])\n",
    "\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if not(y_pred[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with X, y, neighboring y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_x_y_neighboring_y(X_val, y_val, num_x_keys=1):\n",
    "    keys_prioritized = ['word.isupper()', 'word.istitle()', 'word.isdigit()', '+1:word.istitle()', \n",
    "                        '+1:word.isupper()', 'BOS', 'bias',  'word.lower()', 'word[-3:]', 'word[-2:]',\n",
    "                        '+1:word.lower()', 'postag', 'postag[:2]', '+1:postag', '+1:postag[:2]', \n",
    "                        '-1:postag', '-1:postag[:2]', '-1:word.istitle()', '-1:word.lower()',\n",
    "                        '-1:word.isupper()', 'EOS']\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_val_sub = X_val[i][j].copy()\n",
    "            else:\n",
    "                X_val_sub = {k: X_val[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_val[i][j]}\n",
    "            correction_network_input[i].append(X_val_sub)\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j]     \n",
    "            if j >= 1:\n",
    "                correction_network_input[i][j]['y-1'] = y_val_pred[i][j-1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                correction_network_input[i][j]['y-2'] = y_val_pred[i][j-2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 1:\n",
    "                correction_network_input[i][j]['y+1'] = y_val_pred[i][j+1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 2:\n",
    "                correction_network_input[i][j]['y+2'] = y_val_pred[i][j+2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+2'] = 'N'\n",
    "\n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_train_sub = X_train[i][j].copy()\n",
    "            else:\n",
    "                X_train_sub = {k: X_train[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_train[i][j]}\n",
    "            X_expanded[i].append(X_train_sub)\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            if j >= 1:\n",
    "                X_expanded[i][j]['y-1'] = y_train_new[i][j-1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                X_expanded[i][j]['y-2'] = y_train_new[i][j-2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 1:\n",
    "                X_expanded[i][j]['y+1'] = y_train_new[i][j+1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 2:\n",
    "                X_expanded[i][j]['y+2'] = y_train_new[i][j+2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+2'] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with y, neighboring y only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_y_neighboring_y(X_val, y_val, num_ys=1):\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            correction_network_input[i].append(dict())\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j] \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = y_val_pred[i][j-k]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_val_pred[i]) - k:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = y_val_pred[i][j+1]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = 'N'\n",
    "    \n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            X_expanded[i].append(dict())\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = y_train_new[i][j-k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_train_new[i]) - k:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = y_train_new[i][j+k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do results change based on markov blanket size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "X_val_ = X_val[:n]\n",
    "y_val_ = y_val[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.962119861317484\n",
      "FP errors detected: 0.06538228728008799\n",
      "F1 score on trained model: 0.6030578103941252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.70      0.81      0.75      7410\n",
      "       B-gpe       0.86      0.78      0.82      3191\n",
      "       B-org       0.63      0.42      0.50      4056\n",
      "       B-per       0.69      0.61      0.65      3386\n",
      "       B-tim       0.92      0.60      0.73      4042\n",
      "       I-geo       0.58      0.46      0.51      1492\n",
      "       I-gpe       0.04      0.03      0.03        40\n",
      "       I-org       0.57      0.51      0.54      3406\n",
      "       I-per       0.68      0.82      0.74      3524\n",
      "       I-tim       0.86      0.24      0.38      1300\n",
      "           O       0.97      0.99      0.98    177158\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    209005\n",
      "   macro avg       0.68      0.57      0.60    209005\n",
      "weighted avg       0.93      0.94      0.93    209005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppr, pre, pf1 = pseudolabeled_on_validation(X_val_, y_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.8078652798415057\n",
      "FP errors detected: 0.015915022682747443\n",
      "F1 score on trained model: 0.7272779135705676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.77      0.83      0.80      7410\n",
      "       B-gpe       0.97      0.93      0.95      3191\n",
      "       B-org       0.74      0.68      0.71      4056\n",
      "       B-per       0.87      0.70      0.78      3386\n",
      "       B-tim       0.89      0.85      0.87      4042\n",
      "       I-geo       0.63      0.55      0.59      1492\n",
      "       I-gpe       0.00      0.00      0.00        40\n",
      "       I-org       0.78      0.75      0.77      3406\n",
      "       I-per       0.84      0.87      0.86      3524\n",
      "       I-tim       0.68      0.70      0.69      1300\n",
      "           O       0.99      0.99      0.99    177158\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    209005\n",
      "   macro avg       0.74      0.71      0.73    209005\n",
      "weighted avg       0.96      0.96      0.96    209005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_y_neighboring_y(X_val_, y_val_, num_ys=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9507677067855373\n",
      "FP errors detected: 0.010117091141036573\n",
      "F1 score on trained model: 0.7548167667406976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.82      0.90      0.86      7410\n",
      "       B-gpe       0.94      0.93      0.93      3191\n",
      "       B-org       0.75      0.67      0.71      4056\n",
      "       B-per       0.86      0.71      0.78      3386\n",
      "       B-tim       0.93      0.84      0.88      4042\n",
      "       I-geo       0.76      0.69      0.72      1492\n",
      "       I-gpe       0.03      0.03      0.03        40\n",
      "       I-org       0.77      0.75      0.76      3406\n",
      "       I-per       0.84      0.89      0.87      3524\n",
      "       I-tim       0.85      0.72      0.78      1300\n",
      "           O       0.99      0.99      0.99    177158\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    209005\n",
      "   macro avg       0.78      0.74      0.75    209005\n",
      "weighted avg       0.97      0.97      0.97    209005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_x_y_neighboring_y(X_val_, y_val_, num_x_keys=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
