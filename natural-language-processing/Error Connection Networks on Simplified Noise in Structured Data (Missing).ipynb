{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "from scripts import missing_labels\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47959</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47959</td>\n",
       "      <td>35178</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 4020</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>52573</td>\n",
       "      <td>145807</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #     Word      POS      Tag\n",
       "count            47959  1048575  1048575  1048575\n",
       "unique           47959    35178       42       17\n",
       "top     Sentence: 4020      the       NN        O\n",
       "freq                 1    52573   145807   887908"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
     ]
    }
   ],
   "source": [
    "print(df['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tag_set = ['B-geo', 'B-gpe', 'B-org', 'B-per', 'B-tim', 'I-geo',\n",
    "                   'I-gpe', 'I-org', 'I-per', 'I-tim', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "y = [[label if label in reduced_tag_set else 'O' for label in y_i] for y_i in y]  # reduce tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new, error_train_array = missing_labels(y_train, frac=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tags: 819062\n",
      "Num errs: 62398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07618226703228816"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sum([len(a) for a in error_train_array]); print('Num tags:', t)\n",
    "e = sum([sum(a) for a in error_train_array]); print('Num errs:', e)\n",
    "e/t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As compared to 0.04 for RV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37407\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526267386625075\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.86      0.91      0.89      7475\n",
      "       B-gpe       0.97      0.95      0.96      3015\n",
      "       B-org       0.80      0.74      0.77      3989\n",
      "       B-per       0.85      0.83      0.84      3348\n",
      "       B-tim       0.93      0.87      0.90      3996\n",
      "       I-geo       0.82      0.82      0.82      1489\n",
      "       I-gpe       0.89      0.66      0.76        47\n",
      "       I-org       0.82      0.80      0.81      3257\n",
      "       I-per       0.85      0.89      0.87      3405\n",
      "       I-tim       0.83      0.73      0.78      1301\n",
      "           O       0.99      0.99      0.99    177299\n",
      "\n",
      "    accuracy                           0.97    208621\n",
      "   macro avg       0.87      0.83      0.85    208621\n",
      "weighted avg       0.97      0.97      0.97    208621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "clean_precision, clean_recall, clean_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49415149246335804\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train_new)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.91      0.56      0.69      7475\n",
      "       B-gpe       0.99      0.67      0.80      3015\n",
      "       B-org       0.88      0.31      0.46      3989\n",
      "       B-per       0.92      0.30      0.46      3348\n",
      "       B-tim       0.97      0.51      0.67      3996\n",
      "       I-geo       0.91      0.17      0.29      1489\n",
      "       I-gpe       1.00      0.19      0.32        47\n",
      "       I-org       0.85      0.10      0.19      3257\n",
      "       I-per       0.88      0.18      0.30      3405\n",
      "       I-tim       0.93      0.19      0.31      1301\n",
      "           O       0.90      1.00      0.95    177299\n",
      "\n",
      "    accuracy                           0.91    208621\n",
      "   macro avg       0.92      0.38      0.49    208621\n",
      "weighted avg       0.91      0.91      0.88    208621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "dirty_precision, dirty_recall, dirty_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-on SATURDAY , witnesses said at least five people were killed . \n",
      "-the crimes took place in suburban *maryland , outside of WASHINGTON , *d.c. \n",
      "-its session was mostly ceremonial , as talks are still continuing on power-sharing in the new government . \n",
      "-*today 's attacks took place despite an intensified security clampdown in BAGHDAD by U.S. and *iraqi forces . \n",
      "-in order for the merger to overcome anti-trust concerns , rival SOUTHWEST *airlines had to be given take-off and landing rights at the international airport in *newark , NEW JERSEY - just outside NEW YORK CITY . \n",
      "-BRITAIN 's international development *secretary *hilary *benn promised to push ahead with the plan , saying a solution will be found by 2006 with or without the UNITED STATES . \n",
      "-at least one man was killed in the violence . \n",
      "-the website says other campaign workers had no information about the detainees for several hours , but then learned they had been taken to a *minsk prison . \n",
      "-ISRAELI forces have been operating in GAZA since militants abducted an *israeli soldier in *june . \n",
      "-the government 's immigration services agency said FRIDAY , any further visa requests that are received will have to wait until late next year . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_train[i]):\n",
    "        word = word['word.lower()']\n",
    "        if error_train_array[i][w]:\n",
    "            print('*', end='')            \n",
    "        if y_train_new[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-it funds its operations mainly through drug trafficking . \n",
      "-NATO officials say alliance troops *friday raided the home of *mladjen *kenjic , a suspected backer of fugitive wartime *bosnian *serb military commander *general *ratko *mladic . \n",
      "-family members carry coffin of police officer *mohamed *badr for burial in *baghdad insurgents in *iraq launched a third straight day of stepped-up attacks SUNDAY , killing at least nine *iraqis . \n",
      "-defense *minister *carme *chacon said the first 200 troops will leave for the *gulf *of *aden on a frigate and supply vessel this FRIDAY . \n",
      "-the policy allows *cuban refugees who reach U.S. soil to stay in the *united *states , but those intercepted at sea are sent back home . \n",
      "-IRAN 's top nuclear official says his country will not abandon its uranium enrichment program , and that the MIDDLE EAST could become even more unstable if *tehran is referred to the *united *nations *security *council for its nuclear activities . \n",
      "-in particular , the rate of gdp growth is uncertain . \n",
      "-since the 2001 u.s.-led invasion of AFGHANISTAN , hundreds of *taliban and AL-QAIDA suspects have been detained , along with others accused of terrorist activities . \n",
      "-ITALIAN opera star LUCIANO PAVAROTTI has been hospitalized for medical tests in his hometown in northern ITALY . \n",
      "-ISRAELI defense minister *shaul *mofaz and PALESTINIAN MOHAMMED DAHLAN began their talks hours after *palestinians say ISRAELI military gunfire killed a schoolgirl in the *gaza *strip . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_test[i]):\n",
    "        word = word['word.lower()']\n",
    "        if y_pred[i][w] != y_test[i][w]:\n",
    "            print('*', end='')\n",
    "            \n",
    "        if y_pred[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Try to Fix the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the clean F1 is: **0.84** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_method(error_pred, error_array, X, y_corrected):\n",
    "    # measure what percent of errors are fixed\n",
    "    np = 0; nn=0; tp = 0; fp = 0;\n",
    "    for i in range(len(error_pred)):\n",
    "        for j in range(len(error_pred[i])):\n",
    "            if error_pred[i][j] and error_pred[i][j] == error_array[i][j]:\n",
    "                tp += 1\n",
    "            elif error_pred[i][j]:\n",
    "                fp += 1\n",
    "            if error_array[i][j]:\n",
    "                np += 1\n",
    "            else:\n",
    "                nn += 1\n",
    "\n",
    "    \n",
    "    print(\"TP errors detected: {}\".format(tp/np))\n",
    "    print(\"FP errors detected: {}\".format(fp/nn)) \n",
    "\n",
    "    # measure accuracy\n",
    "    crf.fit(X, y_corrected)\n",
    "    y_pred = crf.predict(X_test)\n",
    "    f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(\"F1 score on trained model: {}\".format(f1_score))\n",
    "    \n",
    "    report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision, recall, f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "    print(flat_classification_report(y_test, y_pred))\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudolabeled from Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudolabeled_on_validation(X_val, y_val):\n",
    "    \n",
    "    crf.fit(X_val, y_val)\n",
    "    y_pred = crf.predict(X_train)\n",
    "\n",
    "    error_pred = []\n",
    "    y_corrected = []\n",
    "\n",
    "    for i in range(len(y_pred)):    \n",
    "        error_pred.append([])\n",
    "        y_corrected.append([])\n",
    "\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if not(y_pred[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with X, y, neighboring y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_x_y_neighboring_y(X_val, y_val, num_x_keys=1):\n",
    "    keys_prioritized = ['word.isupper()', 'word.istitle()', 'word.isdigit()', '+1:word.istitle()', \n",
    "                        '+1:word.isupper()', 'BOS', 'bias',  'word.lower()', 'word[-3:]', 'word[-2:]',\n",
    "                        '+1:word.lower()', 'postag', 'postag[:2]', '+1:postag', '+1:postag[:2]', \n",
    "                        '-1:postag', '-1:postag[:2]', '-1:word.istitle()', '-1:word.lower()',\n",
    "                        '-1:word.isupper()', 'EOS']\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_val_sub = X_val[i][j].copy()\n",
    "            else:\n",
    "                X_val_sub = {k: X_val[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_val[i][j]}\n",
    "            correction_network_input[i].append(X_val_sub)\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j]     \n",
    "            if j >= 1:\n",
    "                correction_network_input[i][j]['y-1'] = y_val_pred[i][j-1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                correction_network_input[i][j]['y-2'] = y_val_pred[i][j-2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 1:\n",
    "                correction_network_input[i][j]['y+1'] = y_val_pred[i][j+1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 2:\n",
    "                correction_network_input[i][j]['y+2'] = y_val_pred[i][j+2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+2'] = 'N'\n",
    "\n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_train_sub = X_train[i][j].copy()\n",
    "            else:\n",
    "                X_train_sub = {k: X_train[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_train[i][j]}\n",
    "            X_expanded[i].append(X_train_sub)\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            if j >= 1:\n",
    "                X_expanded[i][j]['y-1'] = y_train_new[i][j-1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                X_expanded[i][j]['y-2'] = y_train_new[i][j-2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 1:\n",
    "                X_expanded[i][j]['y+1'] = y_train_new[i][j+1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 2:\n",
    "                X_expanded[i][j]['y+2'] = y_train_new[i][j+2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+2'] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with y, neighboring y only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_y_neighboring_y(X_val, y_val, num_ys=1):\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            correction_network_input[i].append(dict())\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j] \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = y_val_pred[i][j-k]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_val_pred[i]) - k:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = y_val_pred[i][j+1]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = 'N'\n",
    "    \n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            X_expanded[i].append(dict())\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = y_train_new[i][j-k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_train_new[i]) - k:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = y_train_new[i][j+k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do results change based on markov blanket size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "X_val_ = X_val[:n]\n",
    "y_val_ = y_val[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9823627097291416\n",
      "FP errors detected: 0.067320234743342\n",
      "F1 score on trained model: 0.5965127383566702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.66      0.80      0.72      7631\n",
      "       B-gpe       0.88      0.77      0.83      3217\n",
      "       B-org       0.54      0.41      0.47      4060\n",
      "       B-per       0.69      0.62      0.65      3419\n",
      "       B-tim       0.89      0.58      0.70      4075\n",
      "       I-geo       0.63      0.24      0.35      1443\n",
      "       I-gpe       0.41      0.31      0.35        39\n",
      "       I-org       0.50      0.60      0.54      3393\n",
      "       I-per       0.67      0.74      0.70      3385\n",
      "       I-tim       0.80      0.16      0.26      1293\n",
      "           O       0.98      0.99      0.98    177371\n",
      "\n",
      "   micro avg       0.93      0.93      0.93    209326\n",
      "   macro avg       0.70      0.56      0.60    209326\n",
      "weighted avg       0.93      0.93      0.93    209326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppr, pre, pf1 = pseudolabeled_on_validation(X_val_, y_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.6293878485941705\n",
      "FP errors detected: 0.010975195725812834\n",
      "F1 score on trained model: 0.7898895885893769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.86      0.90      0.88      7631\n",
      "       B-gpe       0.98      0.92      0.95      3217\n",
      "       B-org       0.82      0.66      0.73      4060\n",
      "       B-per       0.84      0.78      0.81      3419\n",
      "       B-tim       0.92      0.82      0.87      4075\n",
      "       I-geo       0.75      0.71      0.73      1443\n",
      "       I-gpe       0.92      0.56      0.70        39\n",
      "       I-org       0.51      0.75      0.61      3393\n",
      "       I-per       0.79      0.77      0.78      3385\n",
      "       I-tim       0.83      0.54      0.66      1293\n",
      "           O       0.98      0.99      0.98    177371\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    209326\n",
      "   macro avg       0.84      0.76      0.79    209326\n",
      "weighted avg       0.96      0.96      0.96    209326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_y_neighboring_y(X_val_, y_val_, num_ys=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9255855236786348\n",
      "FP errors detected: 0.011924788192379266\n",
      "F1 score on trained model: 0.7954438499635597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.84      0.88      0.86      7631\n",
      "       B-gpe       0.97      0.92      0.95      3217\n",
      "       B-org       0.79      0.68      0.73      4060\n",
      "       B-per       0.81      0.77      0.79      3419\n",
      "       B-tim       0.92      0.83      0.88      4075\n",
      "       I-geo       0.85      0.63      0.72      1443\n",
      "       I-gpe       0.58      0.64      0.61        39\n",
      "       I-org       0.71      0.78      0.75      3393\n",
      "       I-per       0.78      0.89      0.83      3385\n",
      "       I-tim       0.85      0.53      0.65      1293\n",
      "           O       0.99      0.99      0.99    177371\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    209326\n",
      "   macro avg       0.83      0.78      0.80    209326\n",
      "weighted avg       0.96      0.96      0.96    209326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_x_y_neighboring_y(X_val_, y_val_, num_x_keys=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Systematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'huntsmen',\n",
       "  'BOS': True,\n",
       "  'bias': 1.0,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word[-3:]': 'The'},\n",
       " {'+1:postag': ',',\n",
       "  '+1:postag[:2]': ',',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': ',',\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'the',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'huntsmen',\n",
       "  'word[-2:]': 'en',\n",
       "  'word[-3:]': 'men'},\n",
       " {'+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'in',\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'huntsmen',\n",
       "  'bias': 1.0,\n",
       "  'postag': ',',\n",
       "  'postag[:2]': ',',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': ',',\n",
       "  'word[-2:]': ',',\n",
       "  'word[-3:]': ','},\n",
       " {'+1:postag': 'PRP$',\n",
       "  '+1:postag[:2]': 'PR',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'their',\n",
       "  '-1:postag': ',',\n",
       "  '-1:postag[:2]': ',',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': ',',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'in',\n",
       "  'word[-2:]': 'in',\n",
       "  'word[-3:]': 'in'},\n",
       " {'+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'haste',\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'in',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'PRP$',\n",
       "  'postag[:2]': 'PR',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'their',\n",
       "  'word[-2:]': 'ir',\n",
       "  'word[-3:]': 'eir'},\n",
       " {'+1:postag': ',',\n",
       "  '+1:postag[:2]': ',',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': ',',\n",
       "  '-1:postag': 'PRP$',\n",
       "  '-1:postag[:2]': 'PR',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'their',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'haste',\n",
       "  'word[-2:]': 'te',\n",
       "  'word[-3:]': 'ste'},\n",
       " {'+1:postag': 'VBD',\n",
       "  '+1:postag[:2]': 'VB',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'overshot',\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'haste',\n",
       "  'bias': 1.0,\n",
       "  'postag': ',',\n",
       "  'postag[:2]': ',',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': ',',\n",
       "  'word[-2:]': ',',\n",
       "  'word[-3:]': ','},\n",
       " {'+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'the',\n",
       "  '-1:postag': ',',\n",
       "  '-1:postag[:2]': ',',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': ',',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'VBD',\n",
       "  'postag[:2]': 'VB',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'overshot',\n",
       "  'word[-2:]': 'ot',\n",
       "  'word[-3:]': 'hot'},\n",
       " {'+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'place',\n",
       "  '-1:postag': 'VBD',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'overshot',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word[-3:]': 'the'},\n",
       " {'+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'of',\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'the',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'place',\n",
       "  'word[-2:]': 'ce',\n",
       "  'word[-3:]': 'ace'},\n",
       " {'+1:postag': 'PRP$',\n",
       "  '+1:postag[:2]': 'PR',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'his',\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'place',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'of',\n",
       "  'word[-2:]': 'of',\n",
       "  'word[-3:]': 'of'},\n",
       " {'+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'concealment',\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'of',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'PRP$',\n",
       "  'postag[:2]': 'PR',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'his',\n",
       "  'word[-2:]': 'is',\n",
       "  'word[-3:]': 'his'},\n",
       " {'+1:postag': '.',\n",
       "  '+1:postag[:2]': '.',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': '.',\n",
       "  '-1:postag': 'PRP$',\n",
       "  '-1:postag[:2]': 'PR',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'his',\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'concealment',\n",
       "  'word[-2:]': 'nt',\n",
       "  'word[-3:]': 'ent'},\n",
       " {'-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'concealment',\n",
       "  'EOS': True,\n",
       "  'bias': 1.0,\n",
       "  'postag': '.',\n",
       "  'postag[:2]': '.',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': '.',\n",
       "  'word[-2:]': '.',\n",
       "  'word[-3:]': '.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_systematic_labels(X, y):\n",
    "    y_new = []\n",
    "    error_array = []\n",
    "    \n",
    "    counter = 0\n",
    "    erasing = False\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "        error_array.append(list())\n",
    "        y_new.append(list())\n",
    "        sentence = TreebankWordDetokenizer().detokenize([t['word.lower()'] for t in X[i]])\n",
    "        doc = nlp(sentence)\n",
    "        ents = list(e.text for e in doc.ents)\n",
    "        word_ents = list()\n",
    "        for e in ents:\n",
    "            word_ents.extend(e.split(' '))\n",
    "        \n",
    "        for j in range(len(y[i])):            \n",
    "            current_tag = y[i][j]\n",
    "            tagset = ['B-org', 'B-per', 'B-tim', 'B-geo', \n",
    "                   'I-org', 'I-per', 'I-tim', 'I-geo'] \n",
    "            if current_tag in tagset and not(X[i][j]['word.lower()'] in word_ents):\n",
    "                y_new[i].append('O')\n",
    "                error_array[i].append(True)                \n",
    "                erasing = True\n",
    "                \n",
    "            else:\n",
    "                error_array[i].append(False)\n",
    "                y_new[i].append(current_tag)\n",
    "                erasing = False\n",
    "        \n",
    "    return y_new, error_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n"
     ]
    }
   ],
   "source": [
    "y_train_new, error_train_array = missing_systematic_labels(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tags: 817737\n",
      "Num errs: 23702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.028984869218342816"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sum([len(a) for a in error_train_array]); print('Num tags:', t)\n",
    "e = sum([sum(a) for a in error_train_array]); print('Num errs:', e)\n",
    "e/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7705203787037477\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train_new)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of scripts failed: Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/a12d/dataopt-private/sequential/scripts.py\", line 186\n",
      "    from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
      "    ^\n",
      "IndentationError: unexpected indent\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.87      0.84      0.86      7563\n",
      "       B-gpe       0.97      0.94      0.96      3236\n",
      "       B-org       0.84      0.56      0.67      4035\n",
      "       B-per       0.80      0.34      0.47      3436\n",
      "       B-tim       0.93      0.85      0.89      4061\n",
      "       I-geo       0.83      0.70      0.76      1470\n",
      "       I-gpe       0.90      0.49      0.63        53\n",
      "       I-org       0.88      0.53      0.66      3405\n",
      "       I-per       0.88      0.83      0.85      3473\n",
      "       I-tim       0.88      0.63      0.74      1259\n",
      "           O       0.96      1.00      0.98    178231\n",
      "\n",
      "    accuracy                           0.95    210222\n",
      "   macro avg       0.89      0.70      0.77    210222\n",
      "weighted avg       0.95      0.95      0.95    210222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'measure_method' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7f7d6e0fbb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgtc_with_x_y_neighboring_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_x_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-901760afcba2>\u001b[0m in \u001b[0;36mgtc_with_x_y_neighboring_y\u001b[0;34m(X_val, y_val, num_x_keys)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0merror_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeasure_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_train_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_corrected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'measure_method' is not defined"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_x_y_neighboring_y(X_val, y_val, num_x_keys=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
