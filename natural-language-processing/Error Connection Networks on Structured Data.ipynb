{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47959</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47959</td>\n",
       "      <td>35178</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 46366</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>52573</td>\n",
       "      <td>145807</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #     Word      POS      Tag\n",
       "count             47959  1048575  1048575  1048575\n",
       "unique            47959    35178       42       17\n",
       "top     Sentence: 46366      the       NN        O\n",
       "freq                  1    52573   145807   887908"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
     ]
    }
   ],
   "source": [
    "print(df['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tag_set = ['B-geo', 'B-gpe', 'B-org', 'B-per', 'B-tim', 'I-geo',\n",
    "                   'I-gpe', 'I-org', 'I-per', 'I-tim', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "y = [[label if label in reduced_tag_set else 'O' for label in y_i] for y_i in y]  # reduce tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMB-Blurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, random\n",
    "\n",
    "def blur_labels(y, frac=0.25):\n",
    "    y_new = []\n",
    "    error_array = []\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        error_array.append(list())\n",
    "        y_new.append(list())\n",
    "        change_steps = 0\n",
    "        change_to = None\n",
    "        \n",
    "        for j in range(len(y[i])):\n",
    "            current_tag = y[i][j]\n",
    "            if change_steps > 0:\n",
    "                change_steps -= 1\n",
    "                y_new[i].append(change_to)\n",
    "                error_array[i].append(True)\n",
    "                continue\n",
    "            \n",
    "            if current_tag.startswith('B') and np.random.random() < frac and j >= 3:\n",
    "                new_tag = current_tag.replace('B', 'I')\n",
    "                y_new[i][j - 3] = current_tag; error_array[i][j-3] = True\n",
    "                y_new[i][j - 2] = new_tag; error_array[i][j-2] = True\n",
    "                y_new[i][j - 1] = new_tag; error_array[i][j-1] = True\n",
    "                y_new[i].append(new_tag); \n",
    "                error_array[i].append(False)\n",
    "                \n",
    "                if (len(y[i])-j)>3 and not(current_tag=='O') and y[i][j+1] == 'O' and np.random.random() < frac:\n",
    "                    change_to = current_tag.replace('B', 'I')\n",
    "                    change_steps = 3\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            if (len(y[i])-j)>3 and not(current_tag=='O') and y[i][j+1] == 'O' and np.random.random() < frac:\n",
    "                change_to = current_tag.replace('B', 'I')\n",
    "                change_steps = 3\n",
    "                y_new[i].append(current_tag); \n",
    "                error_array[i].append(False)\n",
    "                continue\n",
    "            \n",
    "            error_array[i].append(False)\n",
    "            y_new[i].append(current_tag)\n",
    "        \n",
    "    return y_new, error_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new, error_train_array = blur_labels(y_train, frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tags: 755410\n",
      "Num errs: 86447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11443719304748415"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sum([len(a) for a in error_train_array]); print('Num tags:', t)\n",
    "e = sum([sum(a) for a in error_train_array]); print('Num errs:', e)\n",
    "e/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350112325620827\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.86      0.91      0.89      7582\n",
      "       B-gpe       0.97      0.94      0.95      3254\n",
      "       B-org       0.81      0.75      0.78      3966\n",
      "       B-per       0.86      0.82      0.84      3378\n",
      "       B-tim       0.93      0.89      0.91      4058\n",
      "       I-geo       0.84      0.79      0.81      1571\n",
      "       I-gpe       0.87      0.38      0.53        34\n",
      "       I-org       0.80      0.82      0.81      3256\n",
      "       I-per       0.85      0.90      0.87      3499\n",
      "       I-tim       0.82      0.78      0.80      1209\n",
      "           O       0.99      0.99      0.99    176872\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    208679\n",
      "   macro avg       0.87      0.81      0.84    208679\n",
      "weighted avg       0.97      0.97      0.97    208679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6137694734502105\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train_new)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-meanwhile , political *SOURCES *SAY *IRAQI PRIME *MINISTER *NURI *AL-MALIKI will announce his national reconciliation *PLAN *TO *PARLIAMENT SUNDAY . \n",
      "-she is alleged to have passed *CLASSIFIED *INFORMATION *TO PAKISTAN 's intelligence agency . \n",
      "-ZIEMER *, *A *RETIRED U.S. NAVY rear admiral , was previously *EXECUTIVE *DIRECTOR *OF WORLD RELIEF *, *A *PRIVATE AMERICAN disaster relief organization . \n",
      "-the STATE DEPARTMENT says the U.S. ambassador in NICARAGUA is meeting with all parties that have expressed an interest in a \" democratic electoral process . \" \n",
      "-the military had held DR. BESIGYE SINCE NOVEMBER , when he returned from self-imposed exile to run in next month 's elections against PRESIDENT YOWERI MUSEVENI . \n",
      "-they arranged to meet , and the thief was arrested . \n",
      "-however , FIFA officials say the horns *ARE *A *SOUTH AFRICAN tradition and will not be banned . \n",
      "-the PAKISTANI military launched *ITS *OFFENSIVE *IN ORAKZAI to hunt TALIBAN insurgents . \n",
      "-in a separate development , a judge in the *SOUTHERN *CITY *OF BASRA ordered the arrest of two BRITISH soldiers who were freed MONDAY in a controversial BRITISH *RAID *ON *A local prison . \n",
      "-nearly 500 cases of polio have been reported in the country this year , the most in the world by far . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_train[i]):\n",
    "        word = word['word.lower()']\n",
    "        if error_train_array[i][w]:\n",
    "            print('*', end='')            \n",
    "        if y_train_new[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-the two reporters were kidnapped AUGUST 19 by an insurgent group calling itself the ISLAMIC ARMY *of IRAQ . \n",
      "-last month , the U.N. SECURITY COUNCIL adopted a resolution demanding that SYRIA cooperate with the investigation into the FEBRUARY assassination or face possible sanctions . \n",
      "-poor soils and inadequate water supplies hamper the development of agriculture . \n",
      "-IRANIAN authorities arrested BAUER *, *FATTAL *AND *SARAH SHOURD last year on charges of unlawfully crossing into IRANIAN territory from IRAQ . \n",
      "-it will be his first trip abroad since winning *re-election last week . \n",
      "-elsewhere in PAKISTAN 's tribal region , suspected militants released 50 of the 60 people kidnapped at gunpoint in KURRAM on SATURDAY . \n",
      "-ahead of his trip to the region , the military released NATIONAL LEAGUE FOR DEMOCRACY vice chairman TIN OO , after SEVEN years *of *detention . \n",
      "-in *YARACUY , troops surrounded the office of opposition governor EDUARDO LAPI , who vowed not to leave his post until final vote results are issued . \n",
      "-the lower house of parliament overwhelmingly approved the measure during its first reading FRIDAY . \n",
      "-and SUNDAY , a key SYRIAN political group - NATIONAL PROGRESSIVE FRONT - *REJECTED *THE *U.N. report , saying it was based on testimony from people lacking credibility . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_test[i]):\n",
    "        word = word['word.lower()']\n",
    "        if y_pred[i][w] != y_test[i][w]:\n",
    "            print('*', end='')\n",
    "            \n",
    "        if y_pred[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Try to Fix the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the clean F1 is: **0.83** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_method(error_pred, error_array, X, y_corrected):\n",
    "    # measure what percent of errors are fixed\n",
    "    np = 0; nn=0; tp = 0; fp = 0;\n",
    "    for i in range(len(error_pred)):\n",
    "        for j in range(len(error_pred[i])):\n",
    "            if error_pred[i][j] and error_pred[i][j] == error_array[i][j]:\n",
    "                tp += 1\n",
    "            elif error_pred[i][j]:\n",
    "                fp += 1\n",
    "            if error_array[i][j]:\n",
    "                np += 1\n",
    "            else:\n",
    "                nn += 1\n",
    "\n",
    "    \n",
    "    print(\"TP errors detected: {}\".format(tp/np))\n",
    "    print(\"FP errors detected: {}\".format(fp/nn)) \n",
    "\n",
    "    # measure accuracy\n",
    "    crf.fit(X, y_corrected)\n",
    "    y_pred = crf.predict(X_test)\n",
    "    f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(\"F1 score on trained model: {}\".format(f1_score))\n",
    "    \n",
    "    report = flat_classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pred = [[False]*len(i) for i in error_train_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.0\n",
      "FP errors detected: 0.0\n",
      "F1 score on trained model: 0.6137694734502105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.83      0.70      0.76      7582\n",
      "       B-gpe       0.93      0.80      0.86      3254\n",
      "       B-org       0.78      0.59      0.67      3966\n",
      "       B-per       0.82      0.65      0.73      3378\n",
      "       B-tim       0.86      0.72      0.78      4058\n",
      "       I-geo       0.19      0.80      0.31      1571\n",
      "       I-gpe       0.01      0.47      0.02        34\n",
      "       I-org       0.44      0.77      0.56      3256\n",
      "       I-per       0.54      0.86      0.66      3499\n",
      "       I-tim       0.29      0.77      0.43      1209\n",
      "           O       0.99      0.94      0.97    176872\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    208679\n",
      "   macro avg       0.61      0.73      0.61    208679\n",
      "weighted avg       0.95      0.91      0.92    208679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_method(error_pred, error_train_array, X_train, y_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)    \n",
    "X1 = X_train[:n//2]; y1 = y_train_new[:n//2]\n",
    "X2 = X_train[n//2:]; y2 = y_train_new[n//2:]\n",
    "\n",
    "crf.fit(X2, y2)\n",
    "y1_pred = crf.predict(X1)\n",
    "\n",
    "error_pred = []\n",
    "\n",
    "for i in range(len(y1_pred)):    \n",
    "    error_pred.append([])\n",
    "    \n",
    "    for j in range(len(y1_pred[i])):\n",
    "        if not(y1_pred[i][j]==y1[i][j]):\n",
    "            error_pred[i].append(True)\n",
    "        else:\n",
    "            error_pred[i].append(False)\n",
    "\n",
    "crf.fit(X1, y1)\n",
    "y2_pred = crf.predict(X2)\n",
    "\n",
    "for i in range(len(y1_pred)):    \n",
    "    error_pred.append([])\n",
    "    \n",
    "    for j in range(len(y2_pred[i])):\n",
    "        if not(y2_pred[i][j]==y2[i][j]):\n",
    "            error_pred[n//2 + i].append(True)\n",
    "        else:\n",
    "            error_pred[n//2 + i].append(False)\n",
    "\n",
    "y_pred = y1_pred + y2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.0\n",
      "FP errors detected: 0.0\n",
      "F1 score on trained model: 0.11501441942759749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.00      0.00      0.00      7582\n",
      "       B-gpe       0.12      0.23      0.16      3254\n",
      "       B-org       0.27      0.03      0.06      3966\n",
      "       B-per       0.39      0.29      0.33      3378\n",
      "       B-tim       0.35      0.24      0.29      4058\n",
      "       I-geo       0.00      0.00      0.00      1571\n",
      "       I-gpe       0.00      0.50      0.00        34\n",
      "       I-org       0.08      0.14      0.10      3256\n",
      "       I-per       0.19      0.67      0.30      3499\n",
      "       I-tim       0.01      0.72      0.03      1209\n",
      "           O       1.00      0.00      0.00    176872\n",
      "\n",
      "   micro avg       0.03      0.03      0.03    208679\n",
      "   macro avg       0.22      0.26      0.12    208679\n",
      "weighted avg       0.87      0.03      0.02    208679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_method(error_pred, error_train_array, X_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_val, y_val)\n",
    "y_pred = crf.predict(X_train)\n",
    "\n",
    "error_pred = []\n",
    "y_corrected = []\n",
    "\n",
    "for i in range(len(y_pred)):    \n",
    "    error_pred.append([])\n",
    "    y_corrected.append([])\n",
    "    \n",
    "    for j in range(len(y_pred[i])):\n",
    "        if not(y_pred[i][j]==y_train_new[i][j]):\n",
    "            error_pred[i].append(True)\n",
    "        else:\n",
    "            error_pred[i].append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9828681157240853\n",
      "FP errors detected: 0.03904999230151742\n",
      "F1 score on trained model: 0.7130694398505978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.77      0.86      0.81      7582\n",
      "       B-gpe       0.72      0.90      0.80      3254\n",
      "       B-org       0.70      0.59      0.64      3966\n",
      "       B-per       0.68      0.71      0.70      3378\n",
      "       B-tim       0.86      0.79      0.82      4058\n",
      "       I-geo       0.66      0.69      0.67      1571\n",
      "       I-gpe       0.80      0.24      0.36        34\n",
      "       I-org       0.63      0.70      0.66      3256\n",
      "       I-per       0.66      0.92      0.77      3499\n",
      "       I-tim       0.60      0.64      0.62      1209\n",
      "           O       0.99      0.98      0.98    176872\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    208679\n",
      "   macro avg       0.73      0.73      0.71    208679\n",
      "weighted avg       0.95      0.95      0.95    208679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_method(error_pred, error_train_array, X_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What about just the val model?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on trained model: 0.5412043852859015\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_val, y_val)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(\"F1 score on trained model: {}\".format(f1_score))\n",
    "report = flat_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_train, y_train_new)\n",
    "y_val_pred = crf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_network_input = []\n",
    "\n",
    "for i in range(len(y_val_pred)):\n",
    "    correction_network_input.append([])\n",
    "    for j in range(len(y_val_pred[i])):\n",
    "        correction_network_input[i].append(X_val[i][j])\n",
    "        correction_network_input[i][j]['y'] = y_val_pred[i][j]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=False, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(correction_network_input, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_expanded = []\n",
    "\n",
    "for i in range(len(y_train_new)):\n",
    "    X_expanded.append([])\n",
    "    for j in range(len(y_train_new[i])):\n",
    "        X_expanded[i].append(X_train[i][j])\n",
    "        X_expanded[i][j]['y'] = y_train_new[i][j]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go from X_expanded to X_corrected\n",
    "y_corrected = crf.predict(X_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pred = []\n",
    "\n",
    "for i in range(len(y_corrected)):    \n",
    "    error_pred.append([])    \n",
    "    for j in range(len(y_corrected[i])):\n",
    "        if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "            error_pred[i].append(True)\n",
    "        else:\n",
    "            error_pred[i].append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9828681157240853\n",
      "FP errors detected: 0.03904999230151742\n",
      "F1 score on trained model: 0.7130694398505978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.77      0.86      0.81      7582\n",
      "       B-gpe       0.72      0.90      0.80      3254\n",
      "       B-org       0.70      0.59      0.64      3966\n",
      "       B-per       0.68      0.71      0.70      3378\n",
      "       B-tim       0.86      0.79      0.82      4058\n",
      "       I-geo       0.66      0.69      0.67      1571\n",
      "       I-gpe       0.80      0.24      0.36        34\n",
      "       I-org       0.63      0.70      0.66      3256\n",
      "       I-per       0.66      0.92      0.77      3499\n",
      "       I-tim       0.60      0.64      0.62      1209\n",
      "           O       0.99      0.98      0.98    176872\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    208679\n",
      "   macro avg       0.73      0.73      0.71    208679\n",
      "weighted avg       0.95      0.95      0.95    208679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with X, y, neighboring y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_network_input = []\n",
    "\n",
    "for i in range(len(y_val_pred)):\n",
    "    correction_network_input.append([])\n",
    "    for j in range(len(y_val_pred[i])):\n",
    "        correction_network_input[i].append(X_val[i][j])\n",
    "        correction_network_input[i][j]['y'] = y_val_pred[i][j]     \n",
    "        if j >= 1:\n",
    "            correction_network_input[i][j]['y-1'] = y_val_pred[i][j-1]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y-1'] = 'N'\n",
    "        if j >= 2:\n",
    "            correction_network_input[i][j]['y-2'] = y_val_pred[i][j-2]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y-2'] = 'N'\n",
    "        if j < len(y_val_pred[i]) - 1:\n",
    "            correction_network_input[i][j]['y+1'] = y_val_pred[i][j+1]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y+1'] = 'N'\n",
    "        if j < len(y_val_pred[i]) - 2:\n",
    "            correction_network_input[i][j]['y+2'] = y_val_pred[i][j+2]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y+2'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=False, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(correction_network_input, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_expanded = []\n",
    "\n",
    "for i in range(len(y_train_new)):\n",
    "    X_expanded.append([])\n",
    "    for j in range(len(y_train_new[i])):\n",
    "        X_expanded[i].append(X_train[i][j])\n",
    "        X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "        if j >= 1:\n",
    "            X_expanded[i][j]['y-1'] = y_train_new[i][j-1]\n",
    "        else:\n",
    "            X_expanded[i][j]['y-1'] = 'N'\n",
    "        if j >= 2:\n",
    "            X_expanded[i][j]['y-2'] = y_train_new[i][j-2]\n",
    "        else:\n",
    "            X_expanded[i][j]['y-2'] = 'N'\n",
    "        if j < len(y_train_new[i]) - 1:\n",
    "            X_expanded[i][j]['y+1'] = y_train_new[i][j+1]\n",
    "        else:\n",
    "            X_expanded[i][j]['y+1'] = 'N'\n",
    "        if j < len(y_train_new[i]) - 2:\n",
    "            X_expanded[i][j]['y+2'] = y_train_new[i][j+2]\n",
    "        else:\n",
    "            X_expanded[i][j]['y+2'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go from X_expanded to X_corrected\n",
    "y_corrected = crf.predict(X_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pred = []\n",
    "\n",
    "for i in range(len(y_corrected)):    \n",
    "    error_pred.append([])    \n",
    "    for j in range(len(y_corrected[i])):\n",
    "        if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "            error_pred[i].append(True)\n",
    "        else:\n",
    "            error_pred[i].append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9828681157240853\n",
      "FP errors detected: 0.03904999230151742\n",
      "F1 score on trained model: 0.7130694398505978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.77      0.86      0.81      7582\n",
      "       B-gpe       0.72      0.90      0.80      3254\n",
      "       B-org       0.70      0.59      0.64      3966\n",
      "       B-per       0.68      0.71      0.70      3378\n",
      "       B-tim       0.86      0.79      0.82      4058\n",
      "       I-geo       0.66      0.69      0.67      1571\n",
      "       I-gpe       0.80      0.24      0.36        34\n",
      "       I-org       0.63      0.70      0.66      3256\n",
      "       I-per       0.66      0.92      0.77      3499\n",
      "       I-tim       0.60      0.64      0.62      1209\n",
      "           O       0.99      0.98      0.98    176872\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    208679\n",
      "   macro avg       0.73      0.73      0.71    208679\n",
      "weighted avg       0.95      0.95      0.95    208679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with y, neighboring y only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.46778951264936897\n",
      "FP errors detected: 0.012821336905030623\n",
      "F1 score on trained model: 0.010681488434638484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.00      0.00      0.00      7582\n",
      "       B-gpe       0.00      0.00      0.00      3254\n",
      "       B-org       0.06      0.10      0.07      3966\n",
      "       B-per       0.10      0.00      0.00      3378\n",
      "       B-tim       0.00      0.00      0.00      4058\n",
      "       I-geo       0.00      0.00      0.00      1571\n",
      "       I-gpe       0.00      0.00      0.00        34\n",
      "       I-org       0.02      0.99      0.03      3256\n",
      "       I-per       0.11      0.00      0.00      3499\n",
      "       I-tim       0.00      0.00      0.00      1209\n",
      "           O       0.85      0.00      0.01    176872\n",
      "\n",
      "   micro avg       0.02      0.02      0.02    208679\n",
      "   macro avg       0.10      0.10      0.01    208679\n",
      "weighted avg       0.72      0.02      0.01    208679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correction_network_input = []\n",
    "\n",
    "for i in range(len(y_val_pred)):\n",
    "    correction_network_input.append([])\n",
    "    for j in range(len(y_val_pred[i])):\n",
    "        correction_network_input[i].append(dict())\n",
    "        correction_network_input[i][j]['y'] = y_val_pred[i][j]     \n",
    "        if j >= 1:\n",
    "            correction_network_input[i][j]['y-1'] = y_val_pred[i][j-1]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y-1'] = 'N'\n",
    "        if j >= 2:\n",
    "            correction_network_input[i][j]['y-2'] = y_val_pred[i][j-2]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y-2'] = 'N'\n",
    "        if j < len(y_val_pred[i]) - 1:\n",
    "            correction_network_input[i][j]['y+1'] = y_val_pred[i][j+1]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y+1'] = 'N'\n",
    "        if j < len(y_val_pred[i]) - 2:\n",
    "            correction_network_input[i][j]['y+2'] = y_val_pred[i][j+2]\n",
    "        else:\n",
    "            correction_network_input[i][j]['y+2'] = 'N'\n",
    "            \n",
    "crf.fit(correction_network_input, y_val)\n",
    "\n",
    "X_expanded = []\n",
    "\n",
    "for i in range(len(y_train_new)):\n",
    "    X_expanded.append([])\n",
    "    for j in range(len(y_train_new[i])):\n",
    "        X_expanded[i].append(dict())\n",
    "        X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "        if j >= 1:\n",
    "            X_expanded[i][j]['y-1'] = y_train_new[i][j-1]\n",
    "        else:\n",
    "            X_expanded[i][j]['y-1'] = 'N'\n",
    "        if j >= 2:\n",
    "            X_expanded[i][j]['y-2'] = y_train_new[i][j-2]\n",
    "        else:\n",
    "            X_expanded[i][j]['y-2'] = 'N'\n",
    "        if j < len(y_train_new[i]) - 1:\n",
    "            X_expanded[i][j]['y+1'] = y_train_new[i][j+1]\n",
    "        else:\n",
    "            X_expanded[i][j]['y+1'] = 'N'\n",
    "        if j < len(y_train_new[i]) - 2:\n",
    "            X_expanded[i][j]['y+2'] = y_train_new[i][j+2]\n",
    "        else:\n",
    "            X_expanded[i][j]['y+2'] = 'N'\n",
    "            \n",
    "# Go from X_expanded to X_corrected\n",
    "y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "error_pred = []\n",
    "\n",
    "for i in range(len(y_corrected)):    \n",
    "    error_pred.append([])    \n",
    "    for j in range(len(y_corrected[i])):\n",
    "        if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "            error_pred[i].append(True)\n",
    "        else:\n",
    "            error_pred[i].append(False)\n",
    "            \n",
    "measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Back and Analyze What's Going On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible problems:\n",
    "* Debug Kfold\n",
    "* Should do on X_train predictions, not X_train itself\n",
    "* Should decrease size of validation dataset\n",
    "* Try with much simpler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
