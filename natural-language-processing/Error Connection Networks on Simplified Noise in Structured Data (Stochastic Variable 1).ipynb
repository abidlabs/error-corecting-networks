{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47959</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47959</td>\n",
       "      <td>35178</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 10944</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>52573</td>\n",
       "      <td>145807</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #     Word      POS      Tag\n",
       "count             47959  1048575  1048575  1048575\n",
       "unique            47959    35178       42       17\n",
       "top     Sentence: 10944      the       NN        O\n",
       "freq                  1    52573   145807   887908"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
     ]
    }
   ],
   "source": [
    "print(df['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_tag_set = ['B-geo', 'B-gpe', 'B-org', 'B-per', 'B-tim', 'I-geo',\n",
    "                   'I-gpe', 'I-org', 'I-per', 'I-tim', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "y = [[label if label in reduced_tag_set else 'O' for label in y_i] for y_i in y]  # reduce tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMB-Simple-Blurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_labels(y, frac=0.67):\n",
    "    y_new = []\n",
    "    error_array = []\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        error_array.append(list())\n",
    "        y_new.append(list())\n",
    "        change_steps = 0\n",
    "        change_to = None\n",
    "        \n",
    "        for j in range(len(y[i])):\n",
    "            \n",
    "            current_tag = y[i][j]\n",
    "            num_blur = np.random.randint(1,4)\n",
    "            if current_tag=='B-geo' and  j >= num_blur and np.random.random() < frac:\n",
    "                for k in range(num_blur):\n",
    "                    y_new[i][j - k - 1] = current_tag\n",
    "                    error_array[i][j - k - 1] = True\n",
    "                \n",
    "                y_new[i].append(current_tag)\n",
    "                error_array[i].append(False)\n",
    "            else:\n",
    "                error_array[i].append(False)\n",
    "                y_new[i].append(current_tag)\n",
    "        \n",
    "    return y_new, error_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new, error_train_array = blur_labels(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tags: 818841\n",
      "Num errs: 33608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.041043377163576325"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sum([len(a) for a in error_train_array]); print('Num tags:', t)\n",
    "e = sum([sum(a) for a in error_train_array]); print('Num errs:', e)\n",
    "e/t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37407\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8449555980306126\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.87      0.91      0.89      7559\n",
      "       B-gpe       0.96      0.94      0.95      3098\n",
      "       B-org       0.82      0.75      0.78      4061\n",
      "       B-per       0.85      0.83      0.84      3375\n",
      "       B-tim       0.93      0.88      0.90      3994\n",
      "       I-geo       0.84      0.81      0.83      1529\n",
      "       I-gpe       0.78      0.53      0.63        40\n",
      "       I-org       0.83      0.81      0.82      3491\n",
      "       I-per       0.86      0.89      0.87      3426\n",
      "       I-tim       0.82      0.76      0.79      1222\n",
      "           O       0.99      0.99      0.99    177100\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    208895\n",
      "   macro avg       0.87      0.83      0.84    208895\n",
      "weighted avg       0.97      0.97      0.97    208895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "clean_precision, clean_recall, clean_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8082154282084513\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train_new)\n",
    "y_pred = crf.predict(X_test)\n",
    "f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.51      0.88      0.64      7559\n",
      "       B-gpe       0.96      0.93      0.95      3098\n",
      "       B-org       0.78      0.75      0.77      4061\n",
      "       B-per       0.84      0.82      0.83      3375\n",
      "       B-tim       0.92      0.86      0.89      3994\n",
      "       I-geo       0.86      0.73      0.79      1529\n",
      "       I-gpe       0.74      0.50      0.60        40\n",
      "       I-org       0.80      0.82      0.81      3491\n",
      "       I-per       0.85      0.88      0.87      3426\n",
      "       I-tim       0.80      0.75      0.77      1222\n",
      "           O       0.99      0.96      0.98    177100\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    208895\n",
      "   macro avg       0.82      0.81      0.81    208895\n",
      "weighted avg       0.96      0.95      0.95    208895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "dirty_precision, dirty_recall, dirty_f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "print(flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-JAPANESE carmaker TOYOTA MOTOR CORPORATION is reported to be considering letting FUJI HEAVY INDUSTRIES use its hybrid vehicle technology . \n",
      "-last month , PRESIDENT BUSH said the UNITED STATES could not rule out *USING *FORCE *IF IRAN fails to rein in its nuclear plans . \n",
      "-ISAF already *MAINTAINS *SECURITY *IN KABUL and the country 's north and west . \n",
      "-also in *NORTHERN *IRAQ *, KURDISH officials say search teams have located a small plane that crashed THREE days *AGO *NEAR SULAIMANIYAH . \n",
      "-the UNITED STATES says it looks forward to working with a new PAKISTANI government and PRESIDENT PERVEZ MUSHARRAF . \n",
      "-friends and family members of imprisoned opposition activists in BELARUS have sent an open letter to G-8 leaders , calling on them to press for the release of the activists . \n",
      "-settled as early as 1000 B.C. , SAMOA was \" discovered \" by european explorers in the 18TH CENTURY . \n",
      "-forecasters say hurricane otis is gaining strength as it *MOVES *CLOSER *TO MEXICO 's northwestern coast . \n",
      "-moderate cleric MAHDI KARROUBI said TUESDAY that MR. AHMADINEJAD has *PUSHED IRAN into international isolation . \n",
      "-WHITE HOUSE spokesman SCOTT MCCLELLAN told reporters TUESDAY the DEPARTMENT OF DEFENSE is already probing such allegations . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_train[i]):\n",
    "        word = word['word.lower()']\n",
    "        if error_train_array[i][w]:\n",
    "            print('*', end='')            \n",
    "        if y_train_new[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing the predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-officials say MR. BUSH will also call for the further use of hybrid automobiles and those that burn clean diesel fuel by adding them to a list of vehicles eligible for tax credits . \n",
      "-REUTERS news agency reports a new indictment includes charges that *VANUNU , a christian convert , also violated release terms by trying to visit the WEST BANK in DECEMBER to attend a *MIDNIGHT CHRISTMAS religious service . \n",
      "-the action plan released by the JAPANESE health ministry MONDAY anticipates that a quarter of the population , some 32 million people , could become infected and that as many as 6,40,000 people could die . \n",
      "-the ECONOMIC COMMUNITY OF WEST AFRICAN STATES , ECOWAS , says it will not recognize the new government , calling the *EVENTS *IN TOGO a coup . \n",
      "-the ethnically fractured opposition failed to dislodge KANU from power in elections in 1992 AND 1997 , which were marred by violence and fraud , but were viewed as having generally reflected the will of the KENYAN people . \n",
      "-the group has warned the FRENCH government against doing what it described as anything \" stupid . \" \n",
      "-the U.S. EMBASSY in SAUDI ARABIA is warning that extremists may be planning to attack WESTERNERS in the central province of *al-qassim . \n",
      "-while ITALIAN police searched the residences , the *international olympic COMMITTEE conducted unannounced , out-of-competition drug tests on at least six AUSTRIAN cross-country skiers and four biathletes . \n",
      "-change of habit can not alter nature . \n",
      "-MONDAY 's report from a business group , the CONFERENCE BOARD , says its index of leading indicators fell 0.3 percent in MARCH . \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"-\", end=\"\")\n",
    "    for w, word in enumerate(X_test[i]):\n",
    "        word = word['word.lower()']\n",
    "        if y_pred[i][w] != y_test[i][w]:\n",
    "            print('*', end='')\n",
    "            \n",
    "        if y_pred[i][w] == 'O':\n",
    "            print(word.lower(), end=' ')\n",
    "        else:\n",
    "            print(word.upper(), end=' ')            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Try to Fix the Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the clean F1 is: **0.84** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_method(error_pred, error_array, X, y_corrected):\n",
    "    # measure what percent of errors are fixed\n",
    "    np = 0; nn=0; tp = 0; fp = 0;\n",
    "    for i in range(len(error_pred)):\n",
    "        for j in range(len(error_pred[i])):\n",
    "            if error_pred[i][j] and error_pred[i][j] == error_array[i][j]:\n",
    "                tp += 1\n",
    "            elif error_pred[i][j]:\n",
    "                fp += 1\n",
    "            if error_array[i][j]:\n",
    "                np += 1\n",
    "            else:\n",
    "                nn += 1\n",
    "\n",
    "    \n",
    "    print(\"TP errors detected: {}\".format(tp/np))\n",
    "    print(\"FP errors detected: {}\".format(fp/nn)) \n",
    "\n",
    "    # measure accuracy\n",
    "    crf.fit(X, y_corrected)\n",
    "    y_pred = crf.predict(X_test)\n",
    "    f1_score = flat_f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(\"F1 score on trained model: {}\".format(f1_score))\n",
    "    \n",
    "    report = flat_classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision, recall, f1 = report['B-geo']['precision'], report['B-geo']['recall'], report['B-geo']['f1-score'] \n",
    "    print(flat_classification_report(y_test, y_pred))\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudolabeled from Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudolabeled_on_validation(X_val, y_val):\n",
    "    \n",
    "    crf.fit(X_val, y_val)\n",
    "    y_pred = crf.predict(X_train)\n",
    "\n",
    "    error_pred = []\n",
    "    y_corrected = []\n",
    "\n",
    "    for i in range(len(y_pred)):    \n",
    "        error_pred.append([])\n",
    "        y_corrected.append([])\n",
    "\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if not(y_pred[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with X, y, neighboring y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_x_y_neighboring_y(X_val, y_val, num_x_keys=1):\n",
    "    keys_prioritized = ['word.isupper()', 'word.istitle()', 'word.isdigit()', '+1:word.istitle()', \n",
    "                        '+1:word.isupper()', 'BOS', 'bias',  'word.lower()', 'word[-3:]', 'word[-2:]',\n",
    "                        '+1:word.lower()', 'postag', 'postag[:2]', '+1:postag', '+1:postag[:2]', \n",
    "                        '-1:postag', '-1:postag[:2]', '-1:word.istitle()', '-1:word.lower()',\n",
    "                        '-1:word.isupper()', 'EOS']\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_val_sub = X_val[i][j].copy()\n",
    "            else:\n",
    "                X_val_sub = {k: X_val[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_val[i][j]}\n",
    "            correction_network_input[i].append(X_val_sub)\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j]     \n",
    "            if j >= 1:\n",
    "                correction_network_input[i][j]['y-1'] = y_val_pred[i][j-1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                correction_network_input[i][j]['y-2'] = y_val_pred[i][j-2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 1:\n",
    "                correction_network_input[i][j]['y+1'] = y_val_pred[i][j+1]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_val_pred[i]) - 2:\n",
    "                correction_network_input[i][j]['y+2'] = y_val_pred[i][j+2]\n",
    "            else:\n",
    "                correction_network_input[i][j]['y+2'] = 'N'\n",
    "\n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            if num_x_keys is None:\n",
    "                X_train_sub = X_train[i][j].copy()\n",
    "            else:\n",
    "                X_train_sub = {k: X_train[i][j][k] for k in keys_prioritized[:num_x_keys] if k in X_train[i][j]}\n",
    "            X_expanded[i].append(X_train_sub)\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            if j >= 1:\n",
    "                X_expanded[i][j]['y-1'] = y_train_new[i][j-1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-1'] = 'N'\n",
    "            if j >= 2:\n",
    "                X_expanded[i][j]['y-2'] = y_train_new[i][j-2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y-2'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 1:\n",
    "                X_expanded[i][j]['y+1'] = y_train_new[i][j+1]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+1'] = 'N'\n",
    "            if j < len(y_train_new[i]) - 2:\n",
    "                X_expanded[i][j]['y+2'] = y_train_new[i][j+2]\n",
    "            else:\n",
    "                X_expanded[i][j]['y+2'] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTC with y, neighboring y only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtc_with_y_neighboring_y(X_val, y_val, num_ys=1):\n",
    "    \n",
    "    crf.fit(X_train, y_train_new)\n",
    "    y_val_pred = crf.predict(X_val)\n",
    "\n",
    "    correction_network_input = []\n",
    "\n",
    "    for i in range(len(y_val_pred)):\n",
    "        correction_network_input.append([])\n",
    "        for j in range(len(y_val_pred[i])):\n",
    "            correction_network_input[i].append(dict())\n",
    "            correction_network_input[i][j]['y'] = y_val_pred[i][j] \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = y_val_pred[i][j-k]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_val_pred[i]) - k:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = y_val_pred[i][j+1]\n",
    "                else:\n",
    "                    correction_network_input[i][j]['y+{}'.format(k)] = 'N'\n",
    "    \n",
    "    crf.fit(correction_network_input, y_val)\n",
    "\n",
    "    X_expanded = []\n",
    "\n",
    "    for i in range(len(y_train_new)):\n",
    "        X_expanded.append([])\n",
    "        for j in range(len(y_train_new[i])):\n",
    "            X_expanded[i].append(dict())\n",
    "            X_expanded[i][j]['y'] = y_train_new[i][j]     \n",
    "            for k in range(1, 1+num_ys):\n",
    "                if j >= k:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = y_train_new[i][j-k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y-{}'.format(k)] = 'N'\n",
    "                if j < len(y_train_new[i]) - k:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = y_train_new[i][j+k]\n",
    "                else:\n",
    "                    X_expanded[i][j]['y+{}'.format(k)] = 'N'\n",
    "\n",
    "    # Go from X_expanded to X_corrected\n",
    "    y_corrected = crf.predict(X_expanded)\n",
    "\n",
    "    error_pred = []\n",
    "\n",
    "    for i in range(len(y_corrected)):    \n",
    "        error_pred.append([])    \n",
    "        for j in range(len(y_corrected[i])):\n",
    "            if not(y_corrected[i][j]==y_train_new[i][j]):\n",
    "                error_pred[i].append(True)\n",
    "            else:\n",
    "                error_pred[i].append(False)\n",
    "\n",
    "    return measure_method(error_pred, error_train_array, X_train, y_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do results change based on markov blanket size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "X_val_ = X_val[:n]\n",
    "y_val_ = y_val[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9588788383718162\n",
      "FP errors detected: 0.06478331909127609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on trained model: 0.6001578145171726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\islam\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.66      0.85      0.74      7559\n",
      "       B-gpe       0.87      0.72      0.79      3098\n",
      "       B-org       0.52      0.46      0.49      4061\n",
      "       B-per       0.80      0.51      0.62      3375\n",
      "       B-tim       0.94      0.64      0.76      3994\n",
      "       I-geo       0.59      0.42      0.49      1529\n",
      "       I-gpe       0.00      0.00      0.00        40\n",
      "       I-org       0.51      0.60      0.55      3491\n",
      "       I-per       0.75      0.67      0.71      3426\n",
      "       I-tim       0.83      0.32      0.46      1222\n",
      "           O       0.98      0.99      0.98    177100\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    208895\n",
      "   macro avg       0.68      0.56      0.60    208895\n",
      "weighted avg       0.94      0.94      0.93    208895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppr, pre, pf1 = pseudolabeled_on_validation(X_val_, y_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.7787431563913354\n",
      "FP errors detected: 0.006353528188448524\n",
      "F1 score on trained model: 0.7655365808212864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.84      0.89      0.86      7559\n",
      "       B-gpe       0.97      0.93      0.95      3098\n",
      "       B-org       0.80      0.71      0.75      4061\n",
      "       B-per       0.85      0.81      0.83      3375\n",
      "       B-tim       0.93      0.85      0.89      3994\n",
      "       I-geo       0.83      0.66      0.74      1529\n",
      "       I-gpe       0.00      0.00      0.00        40\n",
      "       I-org       0.75      0.79      0.77      3491\n",
      "       I-per       0.84      0.90      0.87      3426\n",
      "       I-tim       0.82      0.73      0.77      1222\n",
      "           O       0.99      0.99      0.99    177100\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    208895\n",
      "   macro avg       0.78      0.75      0.77    208895\n",
      "weighted avg       0.97      0.97      0.97    208895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_y_neighboring_y(X_val_, y_val_, num_ys=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP errors detected: 0.9390323732444656\n",
      "FP errors detected: 0.0096238950731821\n",
      "F1 score on trained model: 0.7626278975983044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.83      0.91      0.87      7559\n",
      "       B-gpe       0.96      0.93      0.95      3098\n",
      "       B-org       0.80      0.70      0.75      4061\n",
      "       B-per       0.87      0.79      0.83      3375\n",
      "       B-tim       0.93      0.84      0.88      3994\n",
      "       I-geo       0.83      0.68      0.75      1529\n",
      "       I-gpe       0.00      0.00      0.00        40\n",
      "       I-org       0.78      0.79      0.78      3491\n",
      "       I-per       0.84      0.90      0.87      3426\n",
      "       I-tim       0.85      0.62      0.72      1222\n",
      "           O       0.99      0.99      0.99    177100\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    208895\n",
      "   macro avg       0.79      0.74      0.76    208895\n",
      "weighted avg       0.97      0.97      0.97    208895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr, re, f1 = gtc_with_x_y_neighboring_y(X_val_, y_val_, num_x_keys=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
